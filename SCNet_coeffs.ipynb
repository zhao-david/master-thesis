{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pylab\n",
    "import scipy\n",
    "import scipy.signal\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from scipy.integrate import dblquad\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, struct\n",
    "from array import array as pyarray\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "\n",
    "def load_mnist(dataset=\"training\", digits=np.arange(10),\n",
    "               path=r'C:\\Users\\David\\Documents\\ETHZ 2015-2017\\'16 HERBST\\THESIS\\MNIST'):\n",
    "    \"\"\"\n",
    "    Loads MNIST files into 3D numpy arrays\n",
    "\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols), dtype=uint8)\n",
    "    labels = zeros((N, 1), dtype=int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train, labels_train = load_mnist(dataset=\"training\")\n",
    "images_test, labels_test = load_mnist(dataset=\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scattering transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution2D(in1, in2, subsample=1):\n",
    "    raw_out = scipy.signal.convolve2d(in1, in2, mode='full', boundary='fill', fillvalue=0)\n",
    "    \n",
    "    # trim so that output has desired dimensions (assume in1 is image, in2 is filter)\n",
    "    shape = np.shape(in1)\n",
    "    trim_size_x = np.floor(shape[0] / 2)\n",
    "    trim_size_y = np.floor(shape[1] / 2)\n",
    "    trimmed_out = raw_out[trim_size_x:-trim_size_x, trim_size_y:-trim_size_y]\n",
    "    \n",
    "    # subsample the trimmed output\n",
    "    out = trimmed_out[::subsample, ::subsample].copy()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complex_modulus(a):\n",
    "    return np.sqrt(a.real**2 + a.imag**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def morlet_wavelet(u, scale, angle, sigma=0.8):\n",
    "    assert(len(u) == 2)\n",
    "    u = rotation_matrix(angle, radians=False).dot(u)\n",
    "    u = u / scale\n",
    "    c_sigma = (1 + np.exp(-sigma**2) - 2*np.exp(-0.75*sigma**2))**(-0.5)\n",
    "    k_sigma = np.exp(-0.5*sigma**2)\n",
    "    return c_sigma * (np.pi)**(-0.25) * np.exp(-0.5*np.linalg.norm(u)**2) \\\n",
    "        * (np.exp(sum(u)*sigma*1j) - k_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotation_matrix(angle, radians=False):\n",
    "    if not radians:\n",
    "        angle = angle * np.pi / 180\n",
    "    return np.array( [[math.cos(angle),-math.sin(angle)], [math.sin(angle), math.cos(angle)]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# precompute and store wavelets!\n",
    "def precompute_all_wvlts(scales, angles, shape=[28,28]):\n",
    "    all_wvlts = {}\n",
    "    for scale in scales:\n",
    "        for angle in angles:\n",
    "            this_wvlt = np.empty(shape, dtype=complex)\n",
    "            for i in range(shape[0]):\n",
    "                for j in range(shape[1]):\n",
    "                    this_wvlt[i,j] = morlet_wavelet(np.array([i-(shape[0]-1)/2, j-(shape[1]-1)/2]),\n",
    "                                                    scale, angle)\n",
    "                    all_wvlts['(' + str(scale) + ',' + str(angle) + ')'] = this_wvlt\n",
    "    return all_wvlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_window(u, sigma=1):\n",
    "    return np.exp(-0.5 * np.linalg.norm(u) / sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windowed_scattering(image, window_size, window_type='Gaussian', alpha=1):\n",
    "    shape = np.shape(image)\n",
    "    window = np.empty(shape)\n",
    "    \n",
    "    if window_type == 'Gaussian':\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                window[i,j] = gaussian_window(np.array([i-(shape[0]-1)/2, j-(shape[1]-1)/2]))\n",
    "    else:\n",
    "        raise(\"Error: invalid window_type!\")\n",
    "    \n",
    "    # subsample at intervals window_size\n",
    "    return convolution2D(image, window, alpha*2**window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_all_paths(scales=[1,2], angles=[0,15,30,45,60,75,90,105,120,135,150,165], depth=2):\n",
    "    all_paths = OrderedDict()\n",
    "    \n",
    "    for i in range(depth):\n",
    "        all_paths[i] = []\n",
    "        \n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            for scale in scales:\n",
    "                for angle in angles:\n",
    "                    all_paths[i] += ['(' + str(scale) + ',' + str(angle) + ')']\n",
    "        else:\n",
    "            # start from last layer\n",
    "            for path in all_paths[i-1]:\n",
    "                steps = path.split('.')\n",
    "                for scale in scales:\n",
    "                    # frequency decreasing\n",
    "                    if scale < eval(steps[-1])[0]:\n",
    "                        for angle in angles:\n",
    "                            all_paths[i] += [path + '.(' + str(scale) + ',' + str(angle) + ')']\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scattering convolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SCN(image, all_paths, all_wvlts, window_size, alpha=1, window_type='Gaussian',\n",
    "        verbose_scattering_coeffs=False, pooling_type='complex'):\n",
    "    \n",
    "    U_p = {}\n",
    "    U_p[''] = image\n",
    "    if verbose_scattering_coeffs:\n",
    "        output = {}\n",
    "        output[''] = windowed_scattering(image, window_size, window_type, alpha)\n",
    "    else:\n",
    "        output = []\n",
    "        output = np.append(output, windowed_scattering(image, window_size, window_type, alpha).flatten())\n",
    "    \n",
    "    # sort by layer so we can build upon previous layers\n",
    "    for depth, paths in all_paths.items():\n",
    "        for path in paths:\n",
    "\n",
    "            # individual steps in a path\n",
    "            steps = path.split('.')\n",
    "\n",
    "            # previous layers\n",
    "            path_minus_one = '.'.join(steps[:-1])\n",
    "            use_prev = U_p[str(path_minus_one)]\n",
    "\n",
    "            # current layer\n",
    "            curr = eval(steps[-1])\n",
    "            scale = curr[0]\n",
    "            angle = curr[1]\n",
    "\n",
    "            # use precomputed wavelets!\n",
    "            use_wvlt = all_wvlts['(' + str(scale) + ',' + str(angle) + ')']\n",
    "\n",
    "            # convolve previous and current layers\n",
    "            convolved = convolution2D(use_prev, use_wvlt, 1) #alpha*2**scale)\n",
    "\n",
    "            # store wavelet coeffs\n",
    "            U_p[path] = complex_modulus(convolved)\n",
    "\n",
    "            # store output scattering coeffs\n",
    "            if verbose_scattering_coeffs:\n",
    "                output[path] = windowed_scattering(U_p[path], window_size, window_type, alpha)\n",
    "            else:\n",
    "                output = np.append(output, windowed_scattering(U_p[path], window_size, window_type,\n",
    "                                                               alpha).flatten())\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_SCN(images, window_size, scales=[1,2], angles=[0,15,30,45,60,75,90,105,120,135,150,165],\n",
    "            depth=2, alpha=1, window_type='Gaussian'):\n",
    "    \n",
    "    all_paths = produce_all_paths(scales, angles, depth)\n",
    "    assert(type(all_paths) == OrderedDict)\n",
    "    \n",
    "    shape = np.shape(images[0])\n",
    "    all_wvlts = precompute_all_wvlts(scales, angles, shape)\n",
    "    \n",
    "    out = []\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for image in images:\n",
    "        SCN_coeffs = SCN(image=image, all_paths=all_paths, all_wvlts=all_wvlts,\n",
    "                         window_size=window_size, alpha=alpha, window_type=window_type,\n",
    "                         verbose_scattering_coeffs=False, pooling_type='complex')\n",
    "\n",
    "        out.append(SCN_coeffs)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('100 images up to index ' + str(i) + ' took: ' + str(t1-t0) + ' secs!')\n",
    "            t0 = time.time()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### testing SCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images up to index 100 took: 1395.2124772071838 secs!\n",
      "100 images up to index 200 took: 1371.9537830352783 secs!\n",
      "100 images up to index 300 took: 1368.1965279579163 secs!\n",
      "100 images up to index 400 took: 1551.9847929477692 secs!\n",
      "100 images up to index 500 took: 1380.903100013733 secs!\n",
      "100 images up to index 600 took: 1397.2863008975983 secs!\n",
      "100 images up to index 700 took: 1390.7863328456879 secs!\n",
      "100 images up to index 800 took: 1374.1138648986816 secs!\n",
      "100 images up to index 900 took: 1359.5696799755096 secs!\n",
      "100 images up to index 1000 took: 1377.270260810852 secs!\n",
      "100 images up to index 1100 took: 1441.1661019325256 secs!\n",
      "100 images up to index 1200 took: 1431.9936261177063 secs!\n",
      "100 images up to index 1300 took: 1448.6228580474854 secs!\n",
      "100 images up to index 1400 took: 1392.0996580123901 secs!\n",
      "100 images up to index 1500 took: 1379.445240020752 secs!\n",
      "100 images up to index 1600 took: 1400.9124190807343 secs!\n",
      "100 images up to index 1700 took: 1497.1386420726776 secs!\n",
      "100 images up to index 1800 took: 1519.2923901081085 secs!\n",
      "100 images up to index 1900 took: 1640.5739841461182 secs!\n",
      "100 images up to index 2000 took: 1310.5506620407104 secs!\n",
      "100 images up to index 2100 took: 1385.3671369552612 secs!\n",
      "100 images up to index 2200 took: 1377.7272231578827 secs!\n",
      "100 images up to index 2300 took: 1382.8113079071045 secs!\n",
      "100 images up to index 2400 took: 1396.913773059845 secs!\n",
      "100 images up to index 2500 took: 1394.5175371170044 secs!\n",
      "100 images up to index 2600 took: 1384.4793260097504 secs!\n",
      "100 images up to index 2700 took: 1374.1728460788727 secs!\n",
      "100 images up to index 2800 took: 1382.4975209236145 secs!\n",
      "100 images up to index 2900 took: 1384.6227300167084 secs!\n",
      "100 images up to index 3000 took: 1385.9053919315338 secs!\n",
      "100 images up to index 3100 took: 1382.3137829303741 secs!\n",
      "100 images up to index 3200 took: 1389.8169379234314 secs!\n",
      "100 images up to index 3300 took: 1382.6752920150757 secs!\n",
      "100 images up to index 3400 took: 1364.671451807022 secs!\n",
      "100 images up to index 3500 took: 1364.9443759918213 secs!\n",
      "100 images up to index 3600 took: 1367.4363260269165 secs!\n",
      "100 images up to index 3700 took: 1356.7808589935303 secs!\n",
      "100 images up to index 3800 took: 1369.9080700874329 secs!\n",
      "100 images up to index 3900 took: 1351.6392149925232 secs!\n",
      "100 images up to index 4000 took: 1364.8878469467163 secs!\n",
      "100 images up to index 4100 took: 1392.6619009971619 secs!\n",
      "100 images up to index 4200 took: 1402.1203210353851 secs!\n",
      "100 images up to index 4300 took: 1372.9774508476257 secs!\n",
      "100 images up to index 4400 took: 1388.7592589855194 secs!\n",
      "100 images up to index 4500 took: 1379.5240619182587 secs!\n",
      "100 images up to index 4600 took: 1375.3441081047058 secs!\n",
      "100 images up to index 4700 took: 1368.8067200183868 secs!\n",
      "100 images up to index 4800 took: 1366.1999530792236 secs!\n",
      "100 images up to index 4900 took: 1382.0876491069794 secs!\n",
      "100 images up to index 5000 took: 1412.5006020069122 secs!\n"
     ]
    }
   ],
   "source": [
    "imgs_5000 = images_train[:5000]\n",
    "scattering_vecs_5000_sigma08 = run_SCN(imgs_5000, window_size=3, alpha=1)\n",
    "np.savetxt('scattering_vecs_5000_sigma08.txt', np.array(scattering_vecs_5000_sigma08), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images up to index 100 took: 1579.0815739631653 secs!\n",
      "100 images up to index 200 took: 1563.7993190288544 secs!\n",
      "100 images up to index 300 took: 1361.8172109127045 secs!\n",
      "100 images up to index 400 took: 1400.644005060196 secs!\n",
      "100 images up to index 500 took: 1341.5281009674072 secs!\n",
      "100 images up to index 600 took: 1357.610934972763 secs!\n",
      "100 images up to index 700 took: 1342.2015690803528 secs!\n",
      "100 images up to index 800 took: 1344.2649228572845 secs!\n",
      "100 images up to index 900 took: 1346.840627193451 secs!\n",
      "100 images up to index 1000 took: 1349.0115299224854 secs!\n"
     ]
    }
   ],
   "source": [
    "imgs_5000_6000 = images_train[5000:6000]\n",
    "scattering_vecs_5000_6000_sigma08 = run_SCN(imgs_5000_6000, window_size=3, alpha=1)\n",
    "np.savetxt('scattering_vecs_5000_6000_sigma08.txt', np.array(scattering_vecs_5000_6000_sigma08),\n",
    "           delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# generate variation MNIST and coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_transform(image):\n",
    "    noise = np.random.uniform(0,255,(28,28))\n",
    "    image = image + noise\n",
    "    \n",
    "    def cutoff_255(a):\n",
    "        return min(a, 255)\n",
    "    f = np.vectorize(cutoff_255)\n",
    "    \n",
    "    return f(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rand = rand_transform(orig_imgs_6000[0])\n",
    "pylab.imshow(test_rand, cmap=pylab.cm.gray)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rot_transform(image):\n",
    "    angle = 360 * np.random.random_sample()\n",
    "    image = scipy.ndimage.interpolation.rotate(image, angle, reshape=False)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rot = rot_transform(orig_imgs_6000[0])\n",
    "pylab.imshow(test_rot, cmap=pylab.cm.gray)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_imgs_6000 = []\n",
    "rot_imgs_6000 = []\n",
    "for img in orig_imgs_6000:\n",
    "    rand_imgs_6000 += [rand_transform(img)]\n",
    "    rot_imgs_6000 += [rot_transform(img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_imgs_6000 = np.array(rand_imgs_6000).flatten().reshape(6000, 28, 28)\n",
    "rot_imgs_6000 = np.array(rot_imgs_6000).flatten().reshape(6000, 28, 28)\n",
    "np.savetxt('rand_imgs_6000.txt', rand_imgs_6000.reshape(6000,784), delimiter=',')\n",
    "np.savetxt('rot_imgs_6000.txt', rot_imgs_6000.reshape(6000,784), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate SCN coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images up to index 100 took: 1108.8046650886536 secs!\n",
      "100 images up to index 200 took: 1259.133581161499 secs!\n",
      "100 images up to index 300 took: 1284.2534251213074 secs!\n",
      "100 images up to index 400 took: 1133.0228040218353 secs!\n",
      "100 images up to index 500 took: 1183.2477841377258 secs!\n",
      "100 images up to index 600 took: 1262.8646838665009 secs!\n",
      "100 images up to index 700 took: 1346.3921749591827 secs!\n",
      "100 images up to index 800 took: 1076.3713901042938 secs!\n",
      "100 images up to index 900 took: 1106.682126045227 secs!\n",
      "100 images up to index 1000 took: 1145.7803449630737 secs!\n",
      "100 images up to index 1100 took: 1543.8658900260925 secs!\n",
      "100 images up to index 1200 took: 1554.5107798576355 secs!\n",
      "100 images up to index 1300 took: 1533.1439199447632 secs!\n",
      "100 images up to index 1400 took: 1523.428188085556 secs!\n",
      "100 images up to index 1500 took: 1528.9704468250275 secs!\n",
      "100 images up to index 1600 took: 1526.075630903244 secs!\n",
      "100 images up to index 1700 took: 1480.9701437950134 secs!\n",
      "100 images up to index 1800 took: 1514.3771471977234 secs!\n",
      "100 images up to index 1900 took: 1564.291314125061 secs!\n",
      "100 images up to index 2000 took: 1307.5421359539032 secs!\n",
      "100 images up to index 2100 took: 1573.0504789352417 secs!\n",
      "100 images up to index 2200 took: 1573.36248087883 secs!\n",
      "100 images up to index 2300 took: 1406.2727451324463 secs!\n",
      "100 images up to index 2400 took: 1367.2961721420288 secs!\n",
      "100 images up to index 2500 took: 1368.2094190120697 secs!\n",
      "100 images up to index 2600 took: 1376.3335220813751 secs!\n",
      "100 images up to index 2700 took: 1373.1548700332642 secs!\n",
      "100 images up to index 2800 took: 1373.089942932129 secs!\n",
      "100 images up to index 2900 took: 1366.6789951324463 secs!\n",
      "100 images up to index 3000 took: 1374.8514330387115 secs!\n",
      "100 images up to index 3100 took: 1367.5370619297028 secs!\n",
      "100 images up to index 3200 took: 1302.0869479179382 secs!\n",
      "100 images up to index 3300 took: 1382.1818151474 secs!\n",
      "100 images up to index 3400 took: 1374.0250098705292 secs!\n",
      "100 images up to index 3500 took: 1363.7464909553528 secs!\n",
      "100 images up to index 3600 took: 1362.4089179039001 secs!\n",
      "100 images up to index 3700 took: 1209.9960508346558 secs!\n",
      "100 images up to index 3800 took: 1087.727164030075 secs!\n",
      "100 images up to index 3900 took: 1441.329679965973 secs!\n",
      "100 images up to index 4000 took: 1118.1786909103394 secs!\n",
      "100 images up to index 4100 took: 1147.832447052002 secs!\n",
      "100 images up to index 4200 took: 1176.088704109192 secs!\n",
      "100 images up to index 4300 took: 1155.816456079483 secs!\n",
      "100 images up to index 4400 took: 1314.32239818573 secs!\n",
      "100 images up to index 4500 took: 1468.778048992157 secs!\n",
      "100 images up to index 4600 took: 1469.2590990066528 secs!\n",
      "100 images up to index 4700 took: 1454.040843963623 secs!\n",
      "100 images up to index 4800 took: 1431.7343130111694 secs!\n",
      "100 images up to index 4900 took: 1449.9243512153625 secs!\n",
      "100 images up to index 5000 took: 1463.0295150279999 secs!\n",
      "100 images up to index 5100 took: 1454.8227579593658 secs!\n",
      "100 images up to index 5200 took: 1445.4826860427856 secs!\n",
      "100 images up to index 5300 took: 1299.4812428951263 secs!\n",
      "100 images up to index 5400 took: 588.7922821044922 secs!\n",
      "100 images up to index 5500 took: 1003.4496819972992 secs!\n",
      "100 images up to index 5600 took: 1372.6434218883514 secs!\n",
      "100 images up to index 5700 took: 1381.77019906044 secs!\n",
      "100 images up to index 5800 took: 1366.0295538902283 secs!\n",
      "100 images up to index 5900 took: 1369.5054190158844 secs!\n",
      "100 images up to index 6000 took: 1368.1523900032043 secs!\n"
     ]
    }
   ],
   "source": [
    "rand_scattering_vecs_6000 = run_SCN(rand_imgs_6000, window_size=3, alpha=1)\n",
    "np.savetxt('rand_scattering_vecs_6000.txt', np.array(rand_scattering_vecs_6000), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images up to index 100 took: 1131.8400030136108 secs!\n",
      "100 images up to index 200 took: 1070.149099111557 secs!\n",
      "100 images up to index 300 took: 1139.514242887497 secs!\n",
      "100 images up to index 400 took: 1068.753890991211 secs!\n",
      "100 images up to index 500 took: 2064.4166259765625 secs!\n",
      "100 images up to index 600 took: 1533.1503789424896 secs!\n",
      "100 images up to index 700 took: 1212.8181800842285 secs!\n",
      "100 images up to index 800 took: 1066.1626811027527 secs!\n",
      "100 images up to index 900 took: 779.3297641277313 secs!\n",
      "100 images up to index 1000 took: 1495.8728609085083 secs!\n",
      "100 images up to index 1100 took: 972.600583076477 secs!\n",
      "100 images up to index 1200 took: 528.6944859027863 secs!\n",
      "100 images up to index 1300 took: 536.7726781368256 secs!\n",
      "100 images up to index 1400 took: 509.10783100128174 secs!\n",
      "100 images up to index 1500 took: 537.4291200637817 secs!\n",
      "100 images up to index 1600 took: 525.6928341388702 secs!\n",
      "100 images up to index 1700 took: 542.8258640766144 secs!\n",
      "100 images up to index 1800 took: 548.4293978214264 secs!\n",
      "100 images up to index 1900 took: 519.9081830978394 secs!\n",
      "100 images up to index 2000 took: 488.06698298454285 secs!\n",
      "100 images up to index 2100 took: 1314.782171010971 secs!\n",
      "100 images up to index 2200 took: 1537.0264341831207 secs!\n",
      "100 images up to index 2300 took: 1535.3484570980072 secs!\n",
      "100 images up to index 2400 took: 1546.9973168373108 secs!\n",
      "100 images up to index 2500 took: 1543.6062350273132 secs!\n",
      "100 images up to index 2600 took: 1541.119313955307 secs!\n",
      "100 images up to index 2700 took: 1502.344347000122 secs!\n",
      "100 images up to index 2800 took: 1546.5632100105286 secs!\n",
      "100 images up to index 2900 took: 1551.86385512352 secs!\n",
      "100 images up to index 3000 took: 1547.9824738502502 secs!\n",
      "100 images up to index 3100 took: 1552.4660210609436 secs!\n",
      "100 images up to index 3200 took: 1549.3958609104156 secs!\n",
      "100 images up to index 3300 took: 1549.2506449222565 secs!\n",
      "100 images up to index 3400 took: 1525.015604019165 secs!\n",
      "100 images up to index 3500 took: 1540.6910290718079 secs!\n",
      "100 images up to index 3600 took: 1545.740525007248 secs!\n",
      "100 images up to index 3700 took: 1543.4660549163818 secs!\n",
      "100 images up to index 3800 took: 1550.856920003891 secs!\n",
      "100 images up to index 3900 took: 1529.5264959335327 secs!\n",
      "100 images up to index 4000 took: 1425.0940730571747 secs!\n",
      "100 images up to index 4100 took: 1281.4335861206055 secs!\n",
      "100 images up to index 4200 took: 1422.1713018417358 secs!\n",
      "100 images up to index 4300 took: 1417.9861409664154 secs!\n",
      "100 images up to index 4400 took: 1225.9605560302734 secs!\n",
      "100 images up to index 4500 took: 1357.7225468158722 secs!\n",
      "100 images up to index 4600 took: 1048.749764919281 secs!\n",
      "100 images up to index 4700 took: 1229.3321390151978 secs!\n",
      "100 images up to index 4800 took: 1140.7503108978271 secs!\n",
      "100 images up to index 4900 took: 566.5509490966797 secs!\n",
      "100 images up to index 5000 took: 566.5812561511993 secs!\n",
      "100 images up to index 5100 took: 575.1224219799042 secs!\n",
      "100 images up to index 5200 took: 805.0667161941528 secs!\n",
      "100 images up to index 5300 took: 1229.5348088741302 secs!\n",
      "100 images up to index 5400 took: 1168.5827040672302 secs!\n",
      "100 images up to index 5500 took: 1126.3899929523468 secs!\n",
      "100 images up to index 5600 took: 1135.6655039787292 secs!\n",
      "100 images up to index 5700 took: 1152.1983060836792 secs!\n",
      "100 images up to index 5800 took: 1059.4986708164215 secs!\n",
      "100 images up to index 5900 took: 875.5938301086426 secs!\n",
      "100 images up to index 6000 took: 1197.785001039505 secs!\n"
     ]
    }
   ],
   "source": [
    "rot_scattering_vecs_6000 = run_SCN(rot_imgs_6000, window_size=3, alpha=1)\n",
    "np.savetxt('rot_scattering_vecs_6000.txt', np.array(rot_scattering_vecs_6000), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scattering_vecs = np.loadtxt('scattering_vecs_5000_sigma08.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scattering_vecs_rand = np.loadtxt('rand_scattering_vecs_6000.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scattering_vecs_rot = np.loadtxt('rot_scattering_vecs_6000.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# zeros, ones, fives\n",
    "for index in (1,21,56,63,69, 3,6,23,24,59, 0,11,35,47,65):\n",
    "    layer0 = layer0_SCNet_coeffs(index=index)\n",
    "    pylab.imshow(layer0, cmap='gray', interpolation='nearest')\n",
    "    pylab.show()\n",
    "    plot_SCNet_coeffs(index=index, layer=1)\n",
    "    plot_SCNet_coeffs(index=index, layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nines\n",
    "for index in (48, 788):\n",
    "    layer0 = layer0_SCNet_coeffs(index=index)\n",
    "    pylab.imshow(layer0, cmap='gray', interpolation='nearest')\n",
    "    pylab.show()\n",
    "    plot_SCNet_coeffs(index=index, layer=1)\n",
    "    plot_SCNet_coeffs(index=index, layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what does directly taking the window function look like\n",
    "def layer0_SCNet_coeffs(index=0, scattering_vecs=scattering_vecs):\n",
    "    \n",
    "    vec = scattering_vecs[index][:16]\n",
    "    \n",
    "    return np.reshape(vec, (4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer1_SCNet_coeffs(index=0, scattering_vecs=scattering_vecs):\n",
    "    \n",
    "    vec = scattering_vecs[index][16:400]\n",
    "    vec1 = []\n",
    "    \n",
    "    for i in range(24):\n",
    "        vec1 += [np.mean(vec[16*i:16*(i+1)])]\n",
    "    \n",
    "    mean_s1 = np.mean(vec1[:12])\n",
    "    mean_s2 = np.mean(vec1[12:])\n",
    "    mean = np.mean(vec1)\n",
    "    \n",
    "    use1 = vec1[:12] / max(vec1[:12])\n",
    "    use2 = vec1[12:] / max(vec1[12:])\n",
    "    \n",
    "    out = np.append([0], use1)\n",
    "    out = np.append(out, [0])\n",
    "    out = np.append(out, use2)\n",
    "    out = np.append(out, np.repeat([np.mean([np.mean(use1), np.mean(use2)])], 13))\n",
    "    \n",
    "    return np.reshape(out, (3,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer2_SCNet_coeffs(index=0, scattering_vecs=scattering_vecs):\n",
    "    \n",
    "    vec = scattering_vecs[index][400:]\n",
    "    vec2 = []\n",
    "    \n",
    "    for i in range(144):\n",
    "        vec2 += [np.mean(vec[16*i:16*(i+1)])]\n",
    "    \n",
    "    vec2 = vec2 / max(vec2)\n",
    "    mean = np.mean(vec2)\n",
    "    \n",
    "    out = np.append([mean], vec2[:12])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[12:24])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[24:36])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[36:48])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[48:60])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[60:72])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[72:84])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[84:96])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[96:108])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[108:120])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[120:132])\n",
    "    out = np.append(out, [mean])\n",
    "    out = np.append(out, vec2[132:])\n",
    "    out = np.append(out, np.repeat([mean], 13))\n",
    "    \n",
    "    return np.reshape(out, (13,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_SCNet_coeffs(index=0, layer=1):\n",
    "    \n",
    "    if layer == 1:\n",
    "        # values to plot\n",
    "        c = layer1_SCNet_coeffs(index)\n",
    "        \n",
    "        # define grid\n",
    "        th = array([pi/6 * n for n in range(13)])\n",
    "        r = array(range(3))\n",
    "\n",
    "    elif layer == 2:\n",
    "        # values to plot\n",
    "        c = layer2_SCNet_coeffs(index)\n",
    "        \n",
    "        # define grid\n",
    "        th = array([pi/6 * n for n in range(13)])\n",
    "        r = array(range(13))\n",
    "    \n",
    "    ax = subplot(111, projection='polar')\n",
    "    \n",
    "    # The smoothing\n",
    "    TH = cbook.simple_linear_interpolation(th, 10)\n",
    "\n",
    "    # padding C\n",
    "    C = zeros((r.size, TH.size))\n",
    "    oldfill = 0\n",
    "    TH_ = TH.tolist()\n",
    "\n",
    "    for i in range(th.size):\n",
    "        fillto = TH_.index(th[i])\n",
    "\n",
    "        for j, x in enumerate(c[:,i]):\n",
    "            C[j, oldfill:fillto].fill(x)\n",
    "\n",
    "        oldfill = fillto\n",
    "\n",
    "    # The plotting\n",
    "    th, r = meshgrid(TH, r)\n",
    "    ax.pcolormesh(th, r, C)\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
